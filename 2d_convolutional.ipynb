{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZT9nq-70P70K",
    "outputId": "9a32bf97-203c-4ffa-b45c-0339be2dd9f4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import collections\n",
    "import pprint\n",
    "from os import path\n",
    "import json\n",
    "import os\n",
    "import codecs\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jxL4GNoZpvgL",
    "outputId": "679ff145-0e1c-4a48-8d01-1c880218c0cf"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Zf2JG8gG_K",
    "outputId": "e12042bc-f0f2-43b8-90a5-5f16af9d136a"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MiJzAIBda1f",
    "outputId": "0fa4fc88-f6f6-4637-cdc5-5bed3418b8b0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nIyTuqfvuTd"
   },
   "outputs": [],
   "source": [
    "#read csv file\n",
    "with open('./annotations.csv', 'r') as f:\n",
    "  df = pd.read_csv(f,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjzquNm8tLdc",
    "outputId": "1b9f9554-4095-4002-cd4d-c54bf51badf2"
   },
   "outputs": [],
   "source": [
    "#sort\n",
    "df = df.sort_values(by=['mp3_path', 'clip_id'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_s3v2Os2qJx"
   },
   "outputs": [],
   "source": [
    "temp_df = df.drop(columns=['clip_id', 'mp3_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwsGOX2vyK9Q"
   },
   "outputs": [],
   "source": [
    "#Top 50 tags\n",
    "lst = []\n",
    "for i in temp_df.columns:\n",
    "  a = np.sum(np.array(df[i]))\n",
    "  lst.append(a)\n",
    "\n",
    "top_50_indexes = np.argsort(-np.array(lst))[:50]\n",
    "new_df = temp_df.iloc[:,top_50_indexes].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_idb1JUfVON2"
   },
   "outputs": [],
   "source": [
    "test = {'labels': []}\n",
    "\n",
    "for i, j in new_df.iterrows():\n",
    "  test['labels'].append(list(j[0:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zsg-WWmrsuC9"
   },
   "outputs": [],
   "source": [
    "range_a = 0\n",
    "range_b = 0\n",
    "df = df['mp3_path'].values\n",
    "\n",
    "for number in range(len(df)):\n",
    "  if df[number][0] == 'c':\n",
    "    range_a = number\n",
    "    break\n",
    "\n",
    "for number in range(range_a+1, len(df)):\n",
    "  if df[number][0] == 'd':\n",
    "    range_b = number\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1jys_wm9wyu",
    "outputId": "b0d47234-3c89-4034-e152-afa6dfa94988"
   },
   "outputs": [],
   "source": [
    "print(range_a)\n",
    "print(range_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCqEfg9Eoij3"
   },
   "outputs": [],
   "source": [
    "dataset_path = './music'\n",
    "#dataset_path = '/content/drive/MyDrive/MTAT/test_sample'\n",
    "json_path = \"/content/srpa_d.json\"\n",
    "track_duration = 29 # measured in seconds  why is 29 instead of 30?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m047oBd65ORL",
    "outputId": "a2236d89-7c40-4b40-d0a6-b1bf9b540f75"
   },
   "outputs": [],
   "source": [
    "for i in sorted(os.listdir(dataset_path)):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5cqSwiJ1Q11",
    "outputId": "d7da873d-0655-4d2b-dda2-ea254d199076"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in sorted(os.listdir(dataset_path)):\n",
    "  count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dl_-_l1PMRai"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "def upload_data(dataset_path, hop_length=512, num_segments=5, n_fft=2048):\n",
    "\n",
    "  data = {\n",
    "      'train': {\n",
    "      #'Labels': [],\n",
    "      'Mel_Spectrogram': []\n",
    "      },\n",
    "      'validation': {\n",
    "      #'Labels': [],\n",
    "      'Mel_Spectrogram': []\n",
    "      },\n",
    "      'test': {\n",
    "      #'Labels': [],\n",
    "      'Mel_Spectrogram': []   \n",
    "      }\n",
    "  }\n",
    "\n",
    "  mul = 1\n",
    "  \n",
    "  for folder in sorted(os.listdir(dataset_path)[1:]):\n",
    "      print(folder)\n",
    "      counter = 0\n",
    "      for file in sorted(os.listdir(dataset_path + '/' + folder )):\n",
    "          print(file)\n",
    "          if file.startswith('.'):\n",
    "            continue\n",
    "            \n",
    "          if counter == 200*mul:\n",
    "              break\n",
    "          counter += 1 \n",
    "\n",
    "          signal, sr = librosa.load(dataset_path + '/' + folder + '/' + file)\n",
    "\n",
    "          samples_per_segment = (sr*track_duration)/num_segments\n",
    "          num_mel_specs_file = samples_per_segment/hop_length\n",
    "          print(counter)\n",
    "          for i in range(num_segments):\n",
    "              start = int(samples_per_segment * i)\n",
    "              finish = int(start + samples_per_segment)\n",
    "              spectrogram = librosa.feature.melspectrogram(signal[start:finish], sr, n_fft=n_fft, hop_length=hop_length, n_mels=20)\n",
    "\n",
    "              log_spectrogram = scaler.fit_transform(librosa.power_to_db(spectrogram))\n",
    "\n",
    "              if folder < 'c':\n",
    "                data['train']['Mel_Spectrogram'].append(log_spectrogram.tolist())\n",
    "              elif folder == 'c':\n",
    "                data['validation']['Mel_Spectrogram'].append(log_spectrogram.tolist())\n",
    "          #else:\n",
    "            #data['test']['Mel_Spectrogram'].append(log_spectrogram.tolist())\n",
    "      mul = .1\n",
    "     \n",
    "    \n",
    "  #add it to json file \n",
    "  with open('./data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "    \n",
    "    \n",
    "    #spectrogram = librosa.feature.melspectrogram(y=y, sr=sr) #should the spectrogram be transposed? \n",
    "    #Store as JSON file(s)?\n",
    "    # store the name/id\n",
    "    #with open(json_path, \"w\") as fp:\n",
    "        #json.dump(data, fp, indent=4)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "useL1c_QJi7x",
    "outputId": "f33be5e2-59c7-4db1-f5cb-bfa34cbda89e"
   },
   "outputs": [],
   "source": [
    "json_file = upload_data(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hm0RnGz4nb4Q"
   },
   "outputs": [],
   "source": [
    "def load_data(json_path, subset):\n",
    "  with open(json_path,\"r\") as f:\n",
    "    file = json.load(f)\n",
    "\n",
    "  x = file[subset]['Mel_Spectrogram']\n",
    "  #y = file[subset]['Labels']\n",
    "  print(x)\n",
    "  #print(y)\n",
    "\n",
    "  return x#, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26qtrRZkxhOi",
    "outputId": "15aff705-5d9a-4cda-f6ac-c168f7c77ceb"
   },
   "outputs": [],
   "source": [
    "inputs = load_data(\"data.json\", 'train')\n",
    "inputs_valid = load_data(\"data.json\", 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HW6YLQoaSEf",
    "outputId": "fcdaaee5-ffdf-49db-a7db-8b37318e4083"
   },
   "outputs": [],
   "source": [
    "print(np.expand_dims(np.array(inputs), axis=-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWzZV5q1yThn"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7opCsEwjwhJ_"
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(np.repeat(new_df.head(200).values, 5, axis=0))\n",
    "df_valid = pd.DataFrame(np.repeat(new_df.head(20).values, 5, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bK0CYAUlxom1"
   },
   "outputs": [],
   "source": [
    "x_train=np.expand_dims(np.array(inputs), axis=-1)\n",
    "y_train=np.array(df_train)\n",
    "\n",
    "\n",
    "x_valid = np.expand_dims(np.array(inputs_valid), axis=-1)\n",
    "y_valid = np.array(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTn4Ih_E1rLR",
    "outputId": "8fd82383-a35b-4dd5-a881-93560a31a142"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jzPi7w64Hu8"
   },
   "outputs": [],
   "source": [
    "#implementation without keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sl9MLF0J4Ma6"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float32\", [None, 20, 250,1])\n",
    "y = tf.placeholder(\"float32\", [None, 50])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAPfoYv44MXy"
   },
   "outputs": [],
   "source": [
    "def conv2d(x, w, b):\n",
    "  x = tf.nn.conv2d(x,w, padding='SAME')\n",
    "  x = tf.nn.bias_add(x,b)\n",
    "  #x = tf.layers.batch_normalization(x, axis=0)\n",
    "  x, _ = tf.linalg.normalize(x)\n",
    "  return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bta-s4QuNfBd"
   },
   "outputs": [],
   "source": [
    "def max_p_2d(x, k1, k2):\n",
    "  return tf.nn.max_pool2d(x, ksize=[1,2,2,1], strides=[1, k1, k2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RF5zoK32atXW"
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.get_variable('w1', shape=(3,3,1,128), initializer=tf.random_normal_initializer, dtype=tf.float32),\n",
    "    'wc2': tf.get_variable('w2', shape=(3,3,128,384), initializer=tf.random_normal_initializer, dtype=tf.float32),\n",
    "    'wc3': tf.get_variable('w3', shape=(3,3,384,768), initializer=tf.random_normal_initializer, dtype=tf.float32),\n",
    "    'wd1': tf.get_variable('wd1', shape=(3*32*768, 2048), initializer=tf.random_normal_initializer, dtype=tf.float32),\n",
    "    #'wc4': tf.get_variable('w4', shape=(3,3,768,2048), initializer=tf.random_normal, dtype=tf.float64),\n",
    "    'out': tf.get_variable('out', shape=(2048, 50), initializer=tf.random_normal_initializer, dtype=tf.float32)\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('b1', shape=(128), initializer=tf.random_normal_initializer, dtype=tf.float32),\n",
    "    'bc2': tf.get_variable('b2', shape=(384), initializer=tf.random_normal_initializer, dtype=tf.float32),\n",
    "    'bc3': tf.get_variable('b3', shape=(768), initializer=tf.random_normal_initializer, dtype=tf.float32),\n",
    "    'bc4': tf.get_variable('b4', shape=(2048), initializer=tf.random_normal_initializer, dtype=tf.float32),\n",
    "    'out': tf.get_variable('b5', shape=(50), initializer=tf.random_normal_initializer, dtype=tf.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMROXr_BnYGP"
   },
   "outputs": [],
   "source": [
    "def CNN(x, weights, biases):\n",
    "\n",
    "  conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "\n",
    "  conv1 = max_p_2d(conv1, 2, 2)\n",
    "  #conv1 = tf.nn.dropout(conv1, rate = 0.5)\n",
    " \n",
    "  conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "  conv2 = max_p_2d(conv2, 2, 2)\n",
    "  #conv2 =  tf.nn.dropout(conv2, rate = 0.5)\n",
    "\n",
    "  conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "  conv3 = max_p_2d(conv3, 2, 2)\n",
    "  #conv3 =  tf.nn.dropout(conv3, rate = 0.5)\n",
    "  print(conv3.shape)\n",
    "\n",
    "  fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "  fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bc4'])\n",
    "  fc1 = tf.nn.relu(fc1)\n",
    "  fc1 = tf.nn.dropout(fc1, rate=0.5)\n",
    "  print(fc1.shape)\n",
    "\n",
    "  #conv4 = conv2d(conv3, weights['wc4'], biases['bc4'])\n",
    "  #conv4 = max_p_2d(conv4, 2, 5)\n",
    "  #conv4 = tf.nn.dropout(conv4, rate = 0.5)\n",
    "\n",
    "  #print(conv4.shape)\n",
    "  #out = tf.add(tf.matmul(tf.squeeze(conv4,[1]), weights['out']), biases['out']\n",
    "  #out = tf.compat.v1.layers.flatten(out)\n",
    "  out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "  #print(out)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3diXxxB26kW"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 4  \n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "Z8xR1OHXr2Tk",
    "outputId": "3854a1d2-049c-4625-b166-9d067d77e137"
   },
   "outputs": [],
   "source": [
    "\"\"\"num_labels = len(y_train.flatten())\n",
    "num_pos_labels = np.sum(y_train.flatten())\n",
    "num_neg_labels = num_labels-num_pos_labels\n",
    "pos_weight = num_pos_labels/num_neg_labels\n",
    "print(pos_weight)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyiS8qix9JKl",
    "outputId": "606628c1-bca9-4b71-d738-a521158fbd02"
   },
   "outputs": [],
   "source": [
    "pred = CNN(x, weights, biases)\n",
    "\n",
    "#loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "#loss = tf.losses.log_loss(labels=y, predictions=pred)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "accuracy = tf.metrics.auc(labels=y, predictions=tf.round(tf.cast(tf.nn.sigmoid(pred), dtype=tf.int16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "vhYsbIbgVBUR",
    "outputId": "4ec042a8-3e9f-432d-9e72-260f8bee8ff2"
   },
   "outputs": [],
   "source": [
    "## Initializing the variables\n",
    "#init = tf.global_variables_initializer()\n",
    "tf.disable_eager_execution()\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(epochs):\n",
    "      train_loss = []\n",
    "      train_accuracy = []\n",
    "      valid_accuracy = []\n",
    "      #for num in range(x_train.shape[0]):\n",
    "      print(x_train.shape[0])\n",
    "      for num in range(0,(x_train.shape[0]//batch_size)*batch_size,batch_size):\n",
    "        batch_x = x_train[num:num+batch_size,:,:]\n",
    "        batch_y = y_train[num:num+batch_size,:] \n",
    "        #test = sess.run(pred, feed_dict={x:batch_x})\n",
    "        #print(test)\n",
    "        #print(sess.run(tf.round(tf.cast(tf.nn.sigmoid(test).eval(), dtype=tf.int16))))\n",
    "\n",
    "        _, loss_ = sess.run([optimizer, loss], feed_dict={x: batch_x, y:batch_y})\n",
    "        acc = sess.run(accuracy, feed_dict={x:batch_x, y:batch_y})\n",
    "        \n",
    "    \n",
    "        train_accuracy.append(acc)\n",
    "        train_loss.append(loss_)\n",
    "        \n",
    "      print('epoch ',i)\n",
    "      print('accuracy: {}'.format(np.mean(train_accuracy)))\n",
    "      print('loss: {}'.format(np.mean(train_loss)))\n",
    "      \n",
    "      for num in range(0,(x_valid.shape[0]//batch_size)*batch_size,batch_size):\n",
    "        batch_x = x_valid[num:num+batch_size,:,:]\n",
    "        batch_y = y_valid[num:num+batch_size,:] \n",
    "        \n",
    "        acc = sess.run(accuracy, feed_dict={x:batch_x, y:batch_y})\n",
    "        valid_accuracy.append(acc)\n",
    "        \n",
    "      print('accuracy: {}'.format(np.mean(valid_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS7RgIby61uu"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "srpa_Audio_tagging_20211217.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
